import requests 
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import time
import pandas as pd

driver = webdriver.Chrome()
driver.get('https://movie.daum.net/moviedb/grade?movieId=111292')
time.sleep(3)

for k in range(99999):
    try:
        driver.find_element(By.XPATH, '//*[@id="alex-area"]/div/div/div/div[3]/div[1]/button').click() 
        time.sleep(1)
    except Exception as ex:
        break;

html = driver.page_source
soup = BeautifulSoup(html, "lxml")        

rating_list = [] 
review_list = []

box_list= soup.select('.cmt_info')
for box in box_list:
    try :
        review= box.select_one('p.desc_txt').text
    except :
        review= "no review"
    rating= box.select_one('.ratings').text
    
    review_list.append(review)
    rating_list.append(rating)

info = {"rating" : rating_list , "review" : review_list}   

theroundup = pd.DataFrame(info)
theroundup.to_csv("다음관객.csv", encoding = "utf8", index=False)
